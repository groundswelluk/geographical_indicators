{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HQldgb0_HYf"
      },
      "source": [
        "# Creating green and blue space indicators from Sentinel-2 data\n",
        "\n",
        "The notebook will estimate the following statistics for each household, as defined as the Unique Property Reference Number (UPRN), across Cheshire and Merseyside:\n",
        "* Normalised Difference Vegetation Index (NDVI)\n",
        "* Enhanced Vegetation Index (EVI)\n",
        "* Normalised Water Difference Idex (NWDI)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wtkH4vC_-LE"
      },
      "source": [
        "## Set up the environment\n",
        "\n",
        "We will use Google Earth Engine (GEE) to access Sentinel-2 images. The strength of using GEE is that we can store and process all the images in the cloud, saving space. Let's start with installing GEE and arrow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBOUh254_zIB",
        "outputId": "16cd5dfb-818d-4362-de21-6c09f5bc3f34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (14.0.2)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "# ! pip install earthengine-api # Comes already installed in Colab so leave here for local running\n",
        "! pip install pyarrow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crmiuqNIBc7H"
      },
      "source": [
        "Next we need to set up Python for the neccessary packages and link the notebook to our set up Groundswell GEE project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UJVNk8fzBqrB"
      },
      "outputs": [],
      "source": [
        "# Load required libaries\n",
        "import ee\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import time\n",
        "from shapely.geometry import mapping\n",
        "\n",
        "# Set up Google Earth Engine (GEE) module\n",
        "ee.Authenticate(auth_mode = \"colab\") # Links GEE to your Google Account and defines that working in Colab (can change to 'localhost' if working on a local machine)\n",
        "ee.Initialize(project = \"ee-groundswelluk\") # Link to the registered project within GEE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY-pfT9OBrPH"
      },
      "source": [
        "## Process images\n",
        "The first key processing task that we need to undertake is to access the satellite imagery and process it into the neccessary format for generating our indicators. As such, we need to: (i) select which satellite we want to use (Sentinel-2), (ii) define the region and extent of images we need (Cheshire and Merseyside), (iii) select the time period (2024) of interest, (iv) remove any clouds from images so that they do not affect any values, (v) extract the information that we want to extract from the images (NDVI, EVI and NWDI), and (vi) take the median value for the whole time period (i.e., combine the information across multiple images).\n",
        "\n",
        "From my testing, it is more computationally efficient to divide our processing by Local Authority rather than trying to do it for the whole region in one go. So below, we will create and process the image for each Local Authority seperately and then save these to Google Earth Engine. We will link the image values to the household information later.\n",
        "\n",
        "As a rough time guide, it takes ~7 minutes to process all of the images for Liverpool in 2023 in Google Colab / Earth Engine, so should take 35-40 minutes in total."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define bounding box geometries for each area\n",
        "liverpool_bbox = ee.Geometry.Rectangle([-3.012314, 53.324927, -2.808037, 53.479261])\n",
        "sefton_bbox = ee.Geometry.Rectangle([-3.123550, 53.433674, -2.881851, 53.686949])\n",
        "knowsley_bbox = ee.Geometry.Rectangle([-2.940216, 53.313237, -2.682724, 53.512143])\n",
        "wirral_bbox = ee.Geometry.Rectangle([-3.204575, 53.304826, -2.918587, 53.444104])\n",
        "halton_bbox = ee.Geometry.Rectangle([-2.827263, 53.301954, -2.594833, 53.402982])\n",
        "warrington_bbox = ee.Geometry.Rectangle([-2.698860, 53.316518, -2.455444, 53.482325])\n",
        "chester_cheshire_west_bbox = ee.Geometry.Rectangle([-3.124237, 52.964770, -2.327042, 53.326772])\n",
        "cheshire_east_bbox = ee.Geometry.Rectangle([-2.736969, 52.921323, -1.976166, 53.423446])\n",
        "st_helens_bbox = ee.Geometry.Rectangle([-2.845459, 53.351781, -2.526855, 53.555810])\n",
        "\n",
        "# List of bounding boxes\n",
        "areas = [\n",
        "    ('Liverpool', liverpool_bbox),\n",
        "    ('Sefton', sefton_bbox),\n",
        "    ('Knowsley', knowsley_bbox),\n",
        "    ('Wirral', wirral_bbox),\n",
        "    ('Halton', halton_bbox),\n",
        "    ('Warrington', warrington_bbox),\n",
        "    ('Chester_and_Cheshire_West', chester_cheshire_west_bbox),\n",
        "    ('Cheshire_East', cheshire_east_bbox),\n",
        "    ('St_Helens', st_helens_bbox)\n",
        "]\n",
        "\n",
        "# Cloud masking function for Sentinel-2\n",
        "def maskS2clouds(image):\n",
        "    qa = image.select('QA60')\n",
        "    cloudBitMask = ee.Number(2).pow(10).int()\n",
        "    cirrusBitMask = ee.Number(2).pow(11).int()\n",
        "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
        "    return image.updateMask(mask).divide(10000)\n",
        "\n",
        "# Load Sentinel-2 surface reflectance data\n",
        "collection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
        "    .filterDate('2024-01-01', '2024-07-02') \\\n",
        "    .map(maskS2clouds)\n",
        "\n",
        "# Calculate NDVI, EVI, and NDWI\n",
        "def addIndices(image):\n",
        "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
        "    evi = image.expression(\n",
        "        '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n",
        "            'NIR': image.select('B8'),\n",
        "            'RED': image.select('B4'),\n",
        "            'BLUE': image.select('B2')\n",
        "        }).rename('EVI')\n",
        "    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
        "    return image.addBands([ndvi, evi, ndwi])\n",
        "\n",
        "# Iterate over each area, calculate median value and export the data to Earth Engine assets\n",
        "for area_name, bbox in areas:\n",
        "    print(f'Processing {area_name}...')\n",
        "\n",
        "    # Filter collection by bounding box\n",
        "    area_collection = collection.filterBounds(bbox)\n",
        "\n",
        "    # Calculate indices\n",
        "    dataset = area_collection.map(addIndices)\n",
        "\n",
        "    # Calculate median value for each index for the time period within the bounding box\n",
        "    median = dataset.median().clip(bbox)\n",
        "\n",
        "    # Select the bands of interest\n",
        "    bands = median.select(['NDVI', 'EVI', 'NDWI'])\n",
        "\n",
        "    # Export the data to an Earth Engine asset\n",
        "    task = ee.batch.Export.image.toAsset(\n",
        "        image=bands,\n",
        "        description=f'{area_name}_Vegetation_Water_Indices',\n",
        "        assetId=f'projects/ee-groundswelluk/assets/2024/{area_name}_Vegetation_Water_Indices', # Where to save on earth engine\n",
        "        region=bbox,\n",
        "        scale=10,\n",
        "        maxPixels=1e13\n",
        "    )\n",
        "    task.start()\n",
        "\n",
        "    # Monitor the task (let know progress or print any errors)\n",
        "    def monitor_task(task):\n",
        "        while task.active():\n",
        "            print(f'Task {task.status()[\"description\"]} is {task.status()[\"state\"]}') # Print current status of the task (ready or running)\n",
        "            time.sleep(60) # Wait 60 seconds before re-running above\n",
        "        status = task.status()\n",
        "        print(f'Task {status[\"description\"]} completed with status: {status[\"state\"]}') # Print if completed task\n",
        "        if status['state'] != 'COMPLETED': # If not completed\n",
        "            print('Error:', status['error_message'])  # Then print the error associated with this\n",
        "\n",
        "    monitor_task(task)\n",
        "\n"
      ],
      "metadata": {
        "id": "Gq2qVuiK6jzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create household-level indicators\n",
        "Here we take the processed images that we have for each area, load in the points for households, and then estimate the average score for a 300m buffer around each point.\n",
        "\n",
        "I have previously processed the households (UPRNs) so that they are in the neccessary format to help make this next step most efficient here - using `get_uprns_cm.R` (make sure you have run this first). This includes: (i) Using only TOIDs (Topographic Identifers) rather than UPRNs (UPRNs are nested within TOIDs which represent the unique building rather than household - e.g., UPRNs would be the individual flats and the TOID would be the single building). This helps to avoid duplication of estimation for multiple UPRNs in the same location (using TOIDs leads to 23% fewer points to process). (ii)  Calculating a 300m buffer around each point seperately, since this is a computationally expensive task for 1.2M points to do here within this script.\n",
        "\n",
        "We can now estimate the median values of NDVI, EDI and NWDI for all inputs. The code below splits this task up by Local Authority and processes each individually. This was done here because it helps to minimise the memory needs of these operations which can lead to Colab crashing. The code below takes 46 minutes to run in total (about ~7 minutes per Local Authority, depending on their size)."
      ],
      "metadata": {
        "id": "F0WkyuklRNP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mapping of Local Authority codes to shapefile paths\n",
        "shapefile_paths = {\n",
        "    'E06000049': '/content/drive/MyDrive/Papers/GroundsWell/WP4/Satellites/toid_buffers_by_lad/toid_buffer_E06000049.shp',\n",
        "    'E06000050': '/content/drive/MyDrive/Papers/GroundsWell/WP4/Satellites/toid_buffers_by_lad/toid_buffer_E06000050.shp',\n",
        "    'E06000006': '/content/drive/MyDrive/Papers/GroundsWell/WP4/Satellites/toid_buffers_by_lad/toid_buffer_E06000006.shp',\n",
        "    'E08000011': '/content/drive/MyDrive/Papers/GroundsWell/WP4/Satellites/toid_buffers_by_lad/toid_buffer_E08000011.shp',\n",
        "    'E08000012': '/content/drive/MyDrive/Papers/GroundsWell/WP4/Satellites/toid_buffers_by_lad/toid_buffer_E08000012.shp',\n",
        "    'E08000014': '/content/drive/MyDrive/Papers/GroundsWell/WP4/Satellites/toid_buffers_by_lad/toid_buffer_E08000014.shp',\n",
        "    'E08000013': '/content/drive/MyDrive/Papers/GroundsWell/WP4/Satellites/toid_buffers_by_lad/toid_buffer_E08000013.shp',\n",
        "    'E06000007': '/content/drive/MyDrive/Papers/GroundsWell/WP4/Satellites/toid_buffers_by_lad/toid_buffer_E06000007.shp',\n",
        "    'E08000015': '/content/drive/MyDrive/Papers/GroundsWell/WP4/Satellites/toid_buffers_by_lad/toid_buffer_E08000015.shp'\n",
        "}\n",
        "\n",
        "def calculate_medians(geometry, image):\n",
        "    stats = image.reduceRegion(\n",
        "        reducer=ee.Reducer.median(),\n",
        "        geometry=geometry,\n",
        "        scale=10,\n",
        "        maxPixels=1e13\n",
        "    )\n",
        "\n",
        "    # Extract values using getInfo()\n",
        "    ndvi_median = stats.get('NDVI').getInfo()\n",
        "    evi_median = stats.get('EVI').getInfo()\n",
        "    ndwi_median = stats.get('NDWI').getInfo()\n",
        "\n",
        "    return {\n",
        "        'NDVI_median': ndvi_median,\n",
        "        'EVI_median': evi_median,\n",
        "        'NDWI_median': ndwi_median\n",
        "    }\n",
        "\n",
        "# Function to convert Shapely polygon to Earth Engine Geometry\n",
        "def shapely_to_ee_geometry(shapely_geometry):\n",
        "    if shapely_geometry.geom_type == 'Polygon' and shapely_geometry.exterior is not None:\n",
        "        coords = list(shapely_geometry.exterior.coords)\n",
        "        ee_geometry = ee.Geometry.Polygon(coords)\n",
        "        return ee_geometry\n",
        "    else:\n",
        "        raise ValueError('Invalid Shapely geometry provided.')\n",
        "\n",
        "# Loop through each Local Authority code\n",
        "for la_code, shapefile_path in shapefile_paths.items():\n",
        "    print(f'Processing Local Authority: {la_code}')\n",
        "\n",
        "    # Load GeoDataFrame for the current Local Authority\n",
        "    la_gdf = gpd.read_file(shapefile_path)\n",
        "\n",
        "    # Load the corresponding image\n",
        "    area_name = la_code_to_image[la_code]\n",
        "    image = ee.Image(f'projects/ee-groundswelluk/assets/2024/{area_name}_Vegetation_Water_Indices')\n",
        "\n",
        "    results_list = []\n",
        "    # Iterate over each row in the GeoDataFrame\n",
        "    for index, row in la_gdf.iterrows():\n",
        "        shapely_geometry = row['geometry']\n",
        "\n",
        "        # Check if the geometry is a valid Polygon\n",
        "        if shapely_geometry.geom_type == 'Polygon' and shapely_geometry.exterior is not None:\n",
        "            coords = list(shapely_geometry.exterior.coords)\n",
        "            ee_geometry = ee.Geometry.Polygon(coords)\n",
        "\n",
        "            #ee_geometry = shapely_to_ee_geometry(shapely_geometry)\n",
        "            #medians = calculate_medians(ee_geometry, image)\n",
        "\n",
        "            try:\n",
        "                medians = calculate_medians(ee_geometry, image)\n",
        "\n",
        "                result = {\n",
        "                    'TOID': row['TOID'],\n",
        "                    'lad23cd': row['lad23cd'],\n",
        "                    'NDVI_median': medians['NDVI_median'],\n",
        "                    'EVI_median': medians['EVI_median'],\n",
        "                    'NDWI_median': medians['NDWI_median']\n",
        "                }\n",
        "\n",
        "                results_list.append(result)\n",
        "\n",
        "                # Print progress for each buffer processed (optional)\n",
        "                #print(f'Processed buffer {index + 1} of {len(la_gdf)}')\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f'Error processing buffer {index + 1} for {la_code}: {str(e)}')\n",
        "\n",
        "    # Save results for the current Local Authority as CSV\n",
        "    result_df = pd.DataFrame(results_list)\n",
        "    output_path = f'/content/drive/MyDrive/Papers/GroundsWell/WP4/Satellites/processed/{area_name}_Vegetation_Water_Indices_Medians.csv'\n",
        "    result_df.to_csv(output_path, index=False)\n",
        "    print(f'Saved results for Local Authority {la_code} to {output_path}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5s8jc0BYqF8",
        "outputId": "032878df-0b5c-413d-8cbe-fcd285794772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Local Authority: E06000049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that these are all finished, please run the R script `check_toids.R` which will assess whether there are any issues with the files and combine them into a single UPRN level indicator.\n",
        "\n"
      ],
      "metadata": {
        "id": "Cz7iOX1KmMpD"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}