{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HQldgb0_HYf"
      },
      "source": [
        "# Creating green and blue space indicators from Sentinel-2 data\n",
        "\n",
        "The notebook will estimate the following statistics for each household, as defined as the Unique Property Reference Number (UPRN), across Cheshire and Merseyside:\n",
        "* Normalised Difference Vegetation Index (NDVI)\n",
        "* Enhanced Vegetation Index (EVI)\n",
        "* Normalised Water Difference Idex (NWDI)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wtkH4vC_-LE"
      },
      "source": [
        "## Set up the environment\n",
        "\n",
        "We will use Google Earth Engine (GEE) to access Sentinel-2 images. The strength of using GEE is that we can store and process all the images in the cloud, saving space. Let's start with installing GEE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBOUh254_zIB"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "# ! pip install earthengine-api # Comes already installed in Colab so leave here for local running"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crmiuqNIBc7H"
      },
      "source": [
        "Next we need to set up Python for the neccessary packages and link the notebook to our set up Groundswell GEE project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJVNk8fzBqrB"
      },
      "outputs": [],
      "source": [
        "# Load required libaries\n",
        "import ee\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import time\n",
        "from shapely.geometry import mapping\n",
        "\n",
        "# Set up Google Earth Engine (GEE) module\n",
        "ee.Authenticate(auth_mode = \"colab\") # Links GEE to your Google Account and defines that working in Colab (can change to 'localhost' if working on a local machine)\n",
        "ee.Initialize(project = \"ee-groundswelluk\") # Link to the registered project within GEE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY-pfT9OBrPH"
      },
      "source": [
        "## Process images\n",
        "The first key processing task that we need to undertake is to access the satellite imagery and process it into the neccessary format for generating our indicators. As such, we need to: (i) select which satellite we want to use (Sentinel-2), (ii) define the region and extent of images we need (Cheshire and Merseyside), (iii) select the time period (2024) of interest, (iv) remove any clouds from images so that they do not affect any values, (v) extract the information that we want to extract from the images (NDVI, EVI and NWDI), and (vi) take the median value for the whole time period (i.e., combine the information across multiple images).\n",
        "\n",
        "From my testing, it is more computationally efficient to divide our processing by Local Authority rather than trying to do it for the whole region in one go. So below, we will create and process the image for each Local Authority seperately and then save these to Google Earth Engine. We will link the image values to the household information later.\n",
        "\n",
        "As a rough time guide, it took me 1 hour 5 mins to run the script."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define bounding box geometries for each area\n",
        "liverpool_bbox = ee.Geometry.Rectangle([-3.03, 53.324927, -2.808037, 53.479261])\n",
        "sefton_bbox = ee.Geometry.Rectangle([-3.123550, 53.433674, -2.881851, 53.686949])\n",
        "knowsley_bbox = ee.Geometry.Rectangle([-2.940216, 53.313237, -2.682724, 53.512143])\n",
        "wirral_bbox = ee.Geometry.Rectangle([-3.23, 53.3, -2.918587, 53.444104])\n",
        "halton_bbox = ee.Geometry.Rectangle([-2.835, 53.301954, -2.594833, 53.402982])\n",
        "warrington_bbox = ee.Geometry.Rectangle([-2.698860, 53.316518, -2.438, 53.482325])\n",
        "chester_cheshire_west_bbox = ee.Geometry.Rectangle([-3.124237, 52.964770, -2.327042, 53.34])\n",
        "cheshire_east_bbox = ee.Geometry.Rectangle([-2.76, 52.921323, -1.976166, 53.423446])\n",
        "st_helens_bbox = ee.Geometry.Rectangle([-2.845459, 53.351781, -2.526855, 53.555810])\n",
        "\n",
        "# List of bounding boxes\n",
        "areas = [\n",
        "    ('Liverpool', liverpool_bbox),\n",
        "    ('Sefton', sefton_bbox),\n",
        "    ('Knowsley', knowsley_bbox),\n",
        "    ('Wirral', wirral_bbox),\n",
        "    ('Halton', halton_bbox),\n",
        "    ('Warrington', warrington_bbox),\n",
        "    ('Chester_and_Cheshire_West', chester_cheshire_west_bbox),\n",
        "    ('Cheshire_East', cheshire_east_bbox),\n",
        "    ('St_Helens', st_helens_bbox)\n",
        "]\n",
        "\n",
        "# Cloud masking function for Sentinel-2\n",
        "def maskS2clouds(image):\n",
        "    qa = image.select('QA60')\n",
        "    cloudBitMask = ee.Number(2).pow(10).int()\n",
        "    cirrusBitMask = ee.Number(2).pow(11).int()\n",
        "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
        "    return image.updateMask(mask).divide(10000)\n",
        "\n",
        "# Load Sentinel-2 surface reflectance data\n",
        "collection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
        "    .filterDate('2024-05-01', '2024-09-30') \\\n",
        "    .map(maskS2clouds)\n",
        "\n",
        "# Calculate NDVI, EVI, and NDWI\n",
        "def addIndices(image):\n",
        "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
        "    evi = image.expression(\n",
        "        '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n",
        "            'NIR': image.select('B8'),\n",
        "            'RED': image.select('B4'),\n",
        "            'BLUE': image.select('B2')\n",
        "        }).rename('EVI')\n",
        "    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
        "    return image.addBands([ndvi, evi, ndwi])\n",
        "\n",
        "# Iterate over each area, calculate median value and export the data to Earth Engine assets\n",
        "for area_name, bbox in areas:\n",
        "    print(f'Processing {area_name}...')\n",
        "\n",
        "    # Filter collection by bounding box\n",
        "    area_collection = collection.filterBounds(bbox)\n",
        "\n",
        "    # Calculate indices\n",
        "    dataset = area_collection.map(addIndices)\n",
        "\n",
        "    # Calculate median value for each index for the time period within the bounding box\n",
        "    median = dataset.median().clip(bbox)\n",
        "\n",
        "    # Select the bands of interest\n",
        "    bands = median.select(['NDVI', 'EVI', 'NDWI'])\n",
        "\n",
        "    # Export the data to an Earth Engine asset\n",
        "    task = ee.batch.Export.image.toAsset(\n",
        "        image=bands,\n",
        "        description=f'{area_name}_Vegetation_Water_Indices',\n",
        "        assetId=f'projects/ee-groundswelluk/assets/2024/{area_name}_Vegetation_Water_Indices', # Where to save on earth engine\n",
        "        region=bbox,\n",
        "        scale=10,\n",
        "        maxPixels=1e13\n",
        "    )\n",
        "    task.start()\n",
        "\n",
        "    # Monitor the task (let know progress or print any errors)\n",
        "    def monitor_task(task):\n",
        "        while task.active():\n",
        "            print(f'Task {task.status()[\"description\"]} is {task.status()[\"state\"]}') # Print current status of the task (ready or running)\n",
        "            time.sleep(60) # Wait 60 seconds before re-running above\n",
        "        status = task.status()\n",
        "        print(f'Task {status[\"description\"]} completed with status: {status[\"state\"]}') # Print if completed task\n",
        "        if status['state'] != 'COMPLETED': # If not completed\n",
        "            print('Error:', status['error_message'])  # Then print the error associated with this\n",
        "\n",
        "    monitor_task(task)\n",
        "\n"
      ],
      "metadata": {
        "id": "Gq2qVuiK6jzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create household-level indicators\n",
        "Here we take the processed images that we have for each area, load in the points for households, and then estimate the average score for a 300m buffer around each point.\n",
        "\n",
        "I have previously processed the households (UPRNs) so that they are in the neccessary format to help make this next step most efficient here - using `get_uprns_cm.R` (make sure you have run this first). This includes: (i) Using only TOIDs (Topographic Identifers) rather than UPRNs (UPRNs are nested within TOIDs which represent the unique building rather than household - e.g., UPRNs would be the individual flats and the TOID would be the single building). This helps to avoid duplication of estimation for multiple UPRNs in the same location (using TOIDs leads to 23% fewer points to process). (ii)  Calculating a 300m buffer around each point seperately, since this is a computationally expensive task for 1.2M points to do here within this script.\n",
        "\n",
        "We can now estimate the median values of NDVI, EDI and NWDI for all inputs. The code below splits this task up by Local Authority and processes each individually. This was done here because it helps to minimise the memory needs of these operations which can lead to Colab crashing. The code below takes 46 minutes to run in total (about ~7 minutes per Local Authority, depending on their size)."
      ],
      "metadata": {
        "id": "F0WkyuklRNP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that these are all finished, please run the R script `check_toids.R` which will assess whether there are any issues with the files and combine them into a single UPRN level indicator.\n"
      ],
      "metadata": {
        "id": "-k35XXReMS9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert shapely geometries to ee.FeatureCollection\n",
        "def shapely_to_ee_featurecollection(geometries, toid_values):\n",
        "    features = []\n",
        "    for geom, toid in zip(geometries, toid_values):\n",
        "        geo_json = geom.__geo_interface__\n",
        "        ee_geom = ee.Geometry(geo_json)\n",
        "        feature = ee.Feature(ee_geom)\n",
        "        feature = feature.set('TOID', toid)  # Set TOID value\n",
        "        features.append(feature)\n",
        "    return ee.FeatureCollection(features)\n",
        "\n",
        "# Define the mapping of Local Authority codes to image asset IDs\n",
        "la_code_to_image = {\n",
        "    'E06000049': 'Cheshire_East',\n",
        "    'E06000050': 'Chester_and_Cheshire_West',\n",
        "    'E06000006': 'Halton',\n",
        "    'E08000011': 'Knowsley',\n",
        "    'E08000012': 'Liverpool',\n",
        "    'E08000014': 'Sefton',\n",
        "    'E08000013': 'St_Helens',\n",
        "    'E06000007': 'Warrington',\n",
        "    'E08000015': 'Wirral'\n",
        "}\n",
        "\n",
        "# Function to process a single batch of geometries and export to Google Drive\n",
        "def process_batch_and_export(batch_gdf, image, area_name, batch_num, la_code, batch_size):\n",
        "    batch_geometries = batch_gdf['geometry'].tolist()\n",
        "    toid_values = batch_gdf['TOID'].tolist()\n",
        "\n",
        "    ee_fc = shapely_to_ee_featurecollection(batch_geometries, toid_values)\n",
        "\n",
        "    # Apply reducer to the FeatureCollection\n",
        "    reduced_fc = image.reduceRegions(\n",
        "        collection=ee_fc,\n",
        "        reducer=ee.Reducer.median(),\n",
        "        scale=10\n",
        "    )\n",
        "\n",
        "    # Export the results to Google Drive\n",
        "    folder_path = f'Papers/GroundsWell/WP4/Satellites/processed/batches/{la_code}'\n",
        "    task = ee.batch.Export.table.toDrive(\n",
        "        collection=reduced_fc,\n",
        "        description=f'{area_name}_Vegetation_Water_Indices_Medians_batch_{batch_num}',\n",
        "        folder=folder_path,\n",
        "        fileFormat='CSV'\n",
        "    )\n",
        "    task.start()\n",
        "    print(f'Saved batch {batch_num}')\n",
        "\n",
        "# Function to process a single Local Authority in batches\n",
        "def process_local_authority_in_batches(la_code, batch_size=1000):\n",
        "    area_name = la_code_to_image[la_code]\n",
        "    print(f'Processing Local Authority: {la_code}')\n",
        "\n",
        "    # Load the corresponding image\n",
        "    image = ee.Image(f'projects/ee-groundswelluk/assets/2024/{area_name}_Vegetation_Water_Indices')\n",
        "\n",
        "    # Load the shapefile using geopandas\n",
        "    shapefile_path = f'/content/drive/MyDrive/Papers/GroundsWell/WP4/Satellites/toid_buffers_by_lad/toid_buffer_{la_code}.shp'\n",
        "    gdf = gpd.read_file(shapefile_path)\n",
        "    # gdf = gdf.sample(1000)  # Subset small datasets for testing purposes\n",
        "\n",
        "    # Process in batches\n",
        "    for i in range(0, len(gdf), batch_size):\n",
        "        batch_gdf = gdf.iloc[i:i + batch_size]\n",
        "\n",
        "        # Process batch and export to Google Drive\n",
        "        process_batch_and_export(batch_gdf, image, area_name, i // batch_size + 1, la_code, batch_size)\n",
        "\n",
        "    print('Processing completed!')\n",
        "\n"
      ],
      "metadata": {
        "id": "YLNp73mdUlj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have split the code for each Local Authority individually here so that they can be run independently. It might have been more efficient to place everything into one large loop, but this approach is helpful for any updates after checking the quality of estimates. Just run each code snippet one-by-one to generate the estimates for that particular Local Authority. They each take between 30mins and 1 hour to run (depending on size)."
      ],
      "metadata": {
        "id": "OQGvdLZe78k6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process a single Local Authority in batches\n",
        "process_local_authority_in_batches('E08000015')  # Wirral (~ 2hrs7mins) - done"
      ],
      "metadata": {
        "id": "_GMvAGaMe_EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_local_authority_in_batches('E06000049')  # Cheshire East (2hrs58mins) - done"
      ],
      "metadata": {
        "id": "aMTKpNYl4Ruv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_local_authority_in_batches('E06000050')  # Chester and Cheshire West (2hrs41) - done"
      ],
      "metadata": {
        "id": "fT9qk7ID4UU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62141a9b-0180-4f0f-c0d6-e35625e0d863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Local Authority: E06000050\n",
            "Saved batch 1\n",
            "Saved batch 2\n",
            "Saved batch 3\n",
            "Saved batch 4\n",
            "Saved batch 5\n",
            "Saved batch 6\n",
            "Saved batch 7\n",
            "Saved batch 8\n",
            "Saved batch 9\n",
            "Saved batch 10\n",
            "Saved batch 11\n",
            "Saved batch 12\n",
            "Saved batch 13\n",
            "Saved batch 14\n",
            "Saved batch 15\n",
            "Saved batch 16\n",
            "Saved batch 17\n",
            "Saved batch 18\n",
            "Saved batch 19\n",
            "Saved batch 20\n",
            "Saved batch 21\n",
            "Saved batch 22\n",
            "Saved batch 23\n",
            "Saved batch 24\n",
            "Saved batch 25\n",
            "Saved batch 26\n",
            "Saved batch 27\n",
            "Saved batch 28\n",
            "Saved batch 29\n",
            "Saved batch 30\n",
            "Saved batch 31\n",
            "Saved batch 32\n",
            "Saved batch 33\n",
            "Saved batch 34\n",
            "Saved batch 35\n",
            "Saved batch 36\n",
            "Saved batch 37\n",
            "Saved batch 38\n",
            "Saved batch 39\n",
            "Saved batch 40\n",
            "Saved batch 41\n",
            "Saved batch 42\n",
            "Saved batch 43\n",
            "Saved batch 44\n",
            "Saved batch 45\n",
            "Saved batch 46\n",
            "Saved batch 47\n",
            "Saved batch 48\n",
            "Saved batch 49\n",
            "Saved batch 50\n",
            "Saved batch 51\n",
            "Saved batch 52\n",
            "Saved batch 53\n",
            "Saved batch 54\n",
            "Saved batch 55\n",
            "Saved batch 56\n",
            "Saved batch 57\n",
            "Saved batch 58\n",
            "Saved batch 59\n",
            "Saved batch 60\n",
            "Saved batch 61\n",
            "Saved batch 62\n",
            "Saved batch 63\n",
            "Saved batch 64\n",
            "Saved batch 65\n",
            "Saved batch 66\n",
            "Saved batch 67\n",
            "Saved batch 68\n",
            "Saved batch 69\n",
            "Saved batch 70\n",
            "Saved batch 71\n",
            "Saved batch 72\n",
            "Saved batch 73\n",
            "Saved batch 74\n",
            "Saved batch 75\n",
            "Saved batch 76\n",
            "Saved batch 77\n",
            "Saved batch 78\n",
            "Saved batch 79\n",
            "Saved batch 80\n",
            "Saved batch 81\n",
            "Saved batch 82\n",
            "Saved batch 83\n",
            "Saved batch 84\n",
            "Saved batch 85\n",
            "Saved batch 86\n",
            "Saved batch 87\n",
            "Saved batch 88\n",
            "Saved batch 89\n",
            "Saved batch 90\n",
            "Saved batch 91\n",
            "Saved batch 92\n",
            "Saved batch 93\n",
            "Saved batch 94\n",
            "Saved batch 95\n",
            "Saved batch 96\n",
            "Saved batch 97\n",
            "Saved batch 98\n",
            "Saved batch 99\n",
            "Saved batch 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:googleapiclient.http:Sleeping 0.10 seconds before retry 1 of 5 for request: POST https://earthengine.googleapis.com/v1/projects/ee-groundswelluk/table:export?alt=json, after 502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved batch 101\n",
            "Saved batch 102\n",
            "Saved batch 103\n",
            "Saved batch 104\n",
            "Saved batch 105\n",
            "Saved batch 106\n",
            "Saved batch 107\n",
            "Saved batch 108\n",
            "Saved batch 109\n",
            "Saved batch 110\n",
            "Saved batch 111\n",
            "Saved batch 112\n",
            "Saved batch 113\n",
            "Saved batch 114\n",
            "Saved batch 115\n",
            "Saved batch 116\n",
            "Saved batch 117\n",
            "Saved batch 118\n",
            "Saved batch 119\n",
            "Saved batch 120\n",
            "Saved batch 121\n",
            "Saved batch 122\n",
            "Saved batch 123\n",
            "Saved batch 124\n",
            "Saved batch 125\n",
            "Saved batch 126\n",
            "Saved batch 127\n",
            "Saved batch 128\n",
            "Saved batch 129\n",
            "Saved batch 130\n",
            "Saved batch 131\n",
            "Saved batch 132\n",
            "Saved batch 133\n",
            "Saved batch 134\n",
            "Saved batch 135\n",
            "Saved batch 136\n",
            "Saved batch 137\n",
            "Saved batch 138\n",
            "Saved batch 139\n",
            "Saved batch 140\n",
            "Saved batch 141\n",
            "Saved batch 142\n",
            "Saved batch 143\n",
            "Saved batch 144\n",
            "Saved batch 145\n",
            "Saved batch 146\n",
            "Saved batch 147\n",
            "Saved batch 148\n",
            "Saved batch 149\n",
            "Saved batch 150\n",
            "Saved batch 151\n",
            "Saved batch 152\n",
            "Saved batch 153\n",
            "Saved batch 154\n",
            "Saved batch 155\n",
            "Saved batch 156\n",
            "Saved batch 157\n",
            "Saved batch 158\n",
            "Saved batch 159\n",
            "Saved batch 160\n",
            "Saved batch 161\n",
            "Saved batch 162\n",
            "Saved batch 163\n",
            "Saved batch 164\n",
            "Saved batch 165\n",
            "Saved batch 166\n",
            "Saved batch 167\n",
            "Saved batch 168\n",
            "Saved batch 169\n",
            "Saved batch 170\n",
            "Saved batch 171\n",
            "Saved batch 172\n",
            "Saved batch 173\n",
            "Saved batch 174\n",
            "Saved batch 175\n",
            "Saved batch 176\n",
            "Saved batch 177\n",
            "Saved batch 178\n",
            "Saved batch 179\n",
            "Saved batch 180\n",
            "Saved batch 181\n",
            "Saved batch 182\n",
            "Saved batch 183\n",
            "Saved batch 184\n",
            "Saved batch 185\n",
            "Saved batch 186\n",
            "Saved batch 187\n",
            "Saved batch 188\n",
            "Saved batch 189\n",
            "Saved batch 190\n",
            "Saved batch 191\n",
            "Saved batch 192\n",
            "Processing completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "process_local_authority_in_batches('E06000006')  # Halton (~25 mins) - done"
      ],
      "metadata": {
        "id": "KKHw2T_i7o6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_local_authority_in_batches('E08000011')  # Knowsley (18mins) - done"
      ],
      "metadata": {
        "id": "zf2h2VBQ7pOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_local_authority_in_batches('E08000012')  # Liverpool (2hours54mins) - done"
      ],
      "metadata": {
        "id": "9_uilu5r7pfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_local_authority_in_batches('E08000014')  # Sefton (31mins) - done"
      ],
      "metadata": {
        "id": "RypTZMCl7p6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_local_authority_in_batches('E08000013')  # St. Helens (23mins) - done"
      ],
      "metadata": {
        "id": "AstIjSoQ7qTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_local_authority_in_batches('E06000007')  # Warrington - done"
      ],
      "metadata": {
        "id": "SOvqtlGE736n"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}